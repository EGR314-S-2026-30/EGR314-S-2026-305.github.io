{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Team 305 DataSheet","text":"Project X Team 305 Submission: January, 18, 2025 Spring - 2026 Arizona State University EGR 314 Dr. Kevin Nichols","tags":["tag1","tag2"]},{"location":"#team-introduction","title":"Team Introduction","text":"<p>This will be updated as part of the preparation for the External Review.    * This needs to be updated to reflect a team introduction.    * Content should also help an unfamiliar reader navigate to areas of interest.</p>","tags":["tag1","tag2"]},{"location":"#team-members-datasheet-links","title":"Team Members Datasheet links","text":"Team Member Individual Datasheet Links Christo Jomon Joseph Christo.Github Ragul Raj RG rrangasa.Github Damian Novgorodov Damian.Github Isaiah Lacombe Isaiah.Github Liam Mabbutt Liam.Github Myles White Myles.Github Arianna Lazaritt Arianna.Github","tags":["tag1","tag2"]},{"location":"01-Organization/Team-Organization/","title":"Team Organization","text":"","tags":["tag1"]},{"location":"01-Organization/Team-Organization/#team-charter","title":"Team Charter","text":"<p>We are here to build a solid project that actually works. We agree to split the work evenly, listen to everyone's ideas, and help each other out when things get stuck. Our goal is to finish with a rover we are proud of and learn good habits that will help us become better engineers.</p>","tags":["tag1"]},{"location":"01-Organization/Team-Organization/#product-mission-statement","title":"Product Mission Statement","text":"<p>Our goal is to prototype a Mars Scout Rover designed to navigate a simulated Martian surface. The system uses a network of custom boards to detect obstacles (like craters or rocks) and automatically adjust speed to avoid collisions, while allowing us to wirelessly steer the rover and view mission data from a laptop base station.</p>","tags":["tag1"]},{"location":"01-Organization/Team-Organization/#other-organizational-information","title":"Other Organizational Information","text":"<p>Other details about the organization structure of the team can be reviewed in \"Appendix: Team Organization Information.\"</p>","tags":["tag1"]},{"location":"02-Concept-Design/Design/","title":"Concept Generation and Design Ideation","text":""},{"location":"02-Concept-Design/Design/#background-reading-and-design-constraints","title":"Background Reading and Design Constraints","text":"<p>From our research we found that a good exploration device needs to be realistic but still easy to understand and use. The person using it should always know what the rover is doing and how their actions affect it. Good feedback through visuals and sounds helps make the system feel natural since operators cant directly touch the rover or see everything its sensing. We also learned that durability and safety are really important. The rover has to handle being used over and over again along with bumps and mistakes without breaking. The moving parts should be protected and the motors should be limited to safe forces. The controls should also go to a safe state if something goes wrong. These are similar to the real challenges engineers deal with when building planetary rovers. Our research also showed that too many controls or hidden features can confuse people. Keeping things simple and giving clear feedback makes it easier for users to understand what is happening and finish tasks. Brainstorming a lot of ideas before picking what to include helped us come up with creative ways to meet these needs.</p>"},{"location":"02-Concept-Design/Design/#goal-of-the-exploration-device","title":"Goal of the Exploration Device","text":"<p>The goal of this exploration device is to simulate a realistic planetary rover with a robotic sampling arm that represents real planetary missions. The rover is meant to show how engineers remotely drive around and collect samples in places where humans cant go. It will demonstrate things like how sensors and motors work together and how decisions are made when theres limited information. The rover shows engineering concepts like how different wheel designs affect movement and how the arm moves and what happens when theres communication delay. Users get to actually use the rover and learn how its design affects what it can do.</p>"},{"location":"02-Concept-Design/Design/#intended-audience","title":"Intended Audience","text":"<p>The main audience for this device is NASA engineers and researchers who want to study or test rover systems in realistic situations. Its designed for people who understand remote control and sensor feedback and robot arms. They want to see how the design of the system affects how well it performs missions. A secondary audience is aerospace engineering students and research partners who can use the rover as a hands on learning tool to explore control strategies and sample collection. The interface is designed to be clear and give all the info through lights and sounds so users can focus on testing and learning.</p>"},{"location":"02-Concept-Design/Design/#generating-ideas","title":"Generating Ideas","text":"<p>This is our raw brainstorm of about 100 ideas. We didn't filter anything out at this stage and just wrote everything down. Our thought process can be found here.</p> <p>Mobility and Navigation  </p> <ol> <li>Tank-style tread drive  </li> <li>Four-wheel independent steering  </li> <li>Obstacle-climbing wheel geometry  </li> <li>Adjustable speed modes  </li> <li>Automatic collision avoidance  </li> <li>Physical boundary markings  </li> <li>LED trail visualization  </li> <li>Compass orientation display  </li> <li>Variable terrain difficulty zones  </li> <li>Rover recovery mode  </li> </ol> <p>Robotic Arm and Sampling  </p> <ol> <li>Two-joint sampling arm  </li> <li>Three-joint articulated arm  </li> <li>Magnetic sample pickup  </li> <li>Soft compliant gripper  </li> <li>Sample storage bin  </li> <li>Force-limited arm motors  </li> <li>Arm-mounted camera  </li> <li>Color-coded gripper tips  </li> <li>Sample-secured feedback indicator  </li> <li>Automatic arm homing  </li> </ol> <p>Sensors and Actuators  </p> <ol> <li>Ultrasonic distance sensors  </li> <li>Color detection sensor  </li> <li>Weight measurement sensor  </li> <li>Temperature sensor  </li> <li>Ambient light sensor  </li> <li>Audio feedback output  </li> <li>LED status indicators  </li> <li>Haptic control feedback  </li> <li>Real-time data visualization  </li> <li>Manual sensor scan mode  </li> </ol> <p>Human-Machine Interface </p> <ol> <li>Large directional control buttons  </li> <li>Joystick-based arm control  </li> <li>Touchscreen display  </li> <li>On-screen arrows and prompts  </li> <li>Icon-based interface design  </li> <li>Task checklist display  </li> <li>Start and reset buttons  </li> <li>Physical emergency stop  </li> <li>Multi-language support  </li> <li>Adjustable difficulty levels  </li> </ol> <p>User Cues and Instruction  </p> <ol> <li>Attention-guiding LED animations  </li> <li>Context-sensitive hints  </li> <li>Animated tutorial loop  </li> <li>Physical arrows and labels  </li> <li>Consistent color coding  </li> <li>Success and error sound cues  </li> <li>Diagram-based instruction panel  </li> <li>Mission briefing screen  </li> <li>Countdown timer  </li> <li>Progress bar visualization  </li> </ol> <p>Durability Safety and Comfort  </p> <ol> <li>Rounded structural edges  </li> <li>Fully enclosed mechanisms  </li> <li>Motor overcurrent protection  </li> <li>Rubberized impact bumpers  </li> <li>Low-speed default operation  </li> <li>Stable weighted base  </li> <li>Height-adjustable control panel  </li> <li>Easy-to-clean materials  </li> <li>Tethered operational area  </li> <li>Child-safe construction materials  </li> </ol> <p>Engagement and Motivation  </p> <ol> <li>Mission-based challenges  </li> <li>Timed objectives  </li> <li>Accuracy-based scoring  </li> <li>Cooperative multi-user mode  </li> <li>Scientist of the Day display  </li> <li>Randomized sample placement  </li> <li>Achievement indicators  </li> <li>Science fact integration  </li> <li>Real-world rover comparisons  </li> <li>Take-home QR code results  </li> </ol> <p>Avoiding Common Interactive Pitfalls </p> <ol> <li>Single clear goal per task  </li> <li>Limited simultaneous controls  </li> <li>Immediate action feedback  </li> <li>No hidden required features  </li> <li>Fail-safe idle behavior  </li> <li>Automatic reset after inactivity  </li> <li>Clear start and end states  </li> <li>Minimal text reliance  </li> <li>Robust repeatable hardware  </li> <li>Clearly defined physical boundaries  </li> </ol> <p>Unconventional and Exploratory Ideas  </p> <ol> <li>Augmented reality overlay  </li> <li>Simulated communication delay  </li> <li>Voice command interaction  </li> <li>AI-guided narration  </li> <li>Simulated environmental hazards  </li> <li>Modular arm tools  </li> <li>Sample contamination simulation  </li> <li>Multi-rover interaction  </li> <li>Competitive mission mode  </li> <li>Night-vision camera mode  </li> </ol> <p>Infrastructure and Connectivity  </p> <ol> <li>Two-way wireless communication  </li> <li>Cloud-based data logging  </li> <li>Instructor control interface  </li> <li>Remote system monitoring  </li> <li>Software update capability  </li> <li>Sensor calibration mode  </li> <li>Diagnostic LED indicators  </li> <li>Data export functionality  </li> <li>Power-saving idle state  </li> <li>Automatic startup self-check  </li> </ol>"},{"location":"02-Concept-Design/Design/#sorting-ranking-and-grouping","title":"Sorting Ranking and Grouping","text":"<p>After getting all those ideas out we organized them into groups and ranked them based on what made the most sense for our project.</p>"},{"location":"02-Concept-Design/Design/#group-1-user-interaction-and-controls","title":"Group 1: User Interaction and Controls","text":"<p>Top Ranked Features</p> <ul> <li>Large directional control buttons  </li> <li>Joystick-based arm control  </li> <li>Touchscreen display  </li> <li>On-screen arrows and prompts  </li> <li>Physical emergency stop  </li> </ul> <p>These features ranked highest because they are clear and easy to use and help prevent confusion.</p>"},{"location":"02-Concept-Design/Design/#group-2-sensors-and-feedback","title":"Group 2: Sensors and Feedback","text":"<p>Top Ranked Features</p> <ul> <li>Ultrasonic distance sensors  </li> <li>Arm-mounted camera  </li> <li>LED status indicators  </li> <li>Audio feedback output  </li> <li>Real-time data visualization  </li> </ul> <p>These give users immediate feedback so they can see how their actions affect the rover.</p>"},{"location":"02-Concept-Design/Design/#group-3-durability-and-safety","title":"Group 3: Durability and Safety","text":"<p>Top Ranked Features</p> <ul> <li>Automatic collision avoidance  </li> <li>Rounded structural edges  </li> <li>Fully enclosed mechanisms  </li> <li>Rubberized impact bumpers  </li> <li>Child-safe construction materials  </li> </ul> <p>Since this will be used by the public including kids we made sure it is tough and safe.</p>"},{"location":"02-Concept-Design/Design/#group-4-engagement-and-learning","title":"Group 4: Engagement and Learning","text":"<p>Top Ranked Features</p> <ul> <li>Mission-based challenges  </li> <li>Animated tutorial loop  </li> <li>Science fact integration  </li> <li>Achievement indicators  </li> </ul> <p>These features keep people interested while also teaching them something.</p>"},{"location":"02-Concept-Design/Design/#product-concept-combinations","title":"Product Concept Combinations","text":"<p>We came up with three different directions we could go:</p> <p>Concept A: Mission Rover Users follow clear missions with step by step instructions and specific goals to complete.  </p> <p>Concept B: Open Exploration Rover Users freely explore and experiment with the rover without set goals or instructions.  </p> <p>Concept C: Collaborative Science Rover Multiple users work together sharing control and discussing data to complete tasks as a team.  </p>"},{"location":"02-Concept-Design/Design/#product-concept-descriptions-and-evaluation","title":"Product Concept Descriptions and Evaluation","text":""},{"location":"02-Concept-Design/Design/#concept-a-mission-rover","title":"Concept A: Mission Rover","text":"<p>This concept gives users short missions to complete. They navigate terrain and collect samples and check sensor readings. Visual and audio cues guide them through each step so they always know what to do. We designed it to avoid common problems like having too many controls active at once or hiding features users need.  </p> <p></p>"},{"location":"02-Concept-Design/Design/#functional-distribution-across-team-members","title":"Functional Distribution Across Team Members","text":"<ul> <li>Internet-based two-way wireless communication handles data transmission and logging and system status reporting  </li> <li>Human-machine interface covers the touchscreen UI and buttons and visual cues and user feedback  </li> <li>Sensor and actuator control manages motors and the robotic arm and sensors and closed-loop responses  </li> <li>System integration and safety handles power management and fault detection and durability testing  </li> </ul>"},{"location":"02-Concept-Design/Design/#design-justification","title":"Design Justification","text":"<ul> <li>Cues include LED animations and on-screen arrows and audio feedback and progress indicators  </li> <li>Controls use large buttons and a joystick to make operation straightforward  </li> <li>Durability and Comfort comes from enclosed mechanisms and current-limited motors and ergonomic layout  </li> <li>Instruction uses a brief mission briefing and looping tutorial so no one needs to explain it  </li> </ul>"},{"location":"02-Concept-Design/Design/#concept-b-open-exploration-rover","title":"Concept B: Open Exploration Rover","text":"<p>The Open Exploration Rover concept focuses on letting users discover things on their own by removing set objectives and letting them freely interact with the rover and its environment. Users can navigate terrain and operate sensors and experiment with what the rover can do at their own pace. This approach encourages curiosity and creativity and self-directed learning but it ranked lower overall because theres more risk of user confusion and lack of clear guidance for first-time users. Without structured goals some users might not understand the rovers purpose or how to actually use its systems.  </p> <p></p>"},{"location":"02-Concept-Design/Design/#functional-distribution-across-team-members_1","title":"Functional Distribution Across Team Members","text":"<ul> <li>Internet-based two-way wireless communication handles real-time telemetry streaming and live sensor data visualization and remote command handling  </li> <li>Human-machine interface provides an open-ended touchscreen UI and manual control inputs and live data dashboards with minimal instructions  </li> <li>Sensor and actuator control gives direct control of motors and robotic arm and cameras and environmental sensors with fewer automated constraints  </li> <li>System integration and safety manages power regulation and collision prevention and emergency stop logic and robustness for unpredictable user behavior  </li> </ul>"},{"location":"02-Concept-Design/Design/#design-justification_1","title":"Design Justification","text":"<ul> <li>Cues are minimal with just raw sensor readouts and subtle status LEDs to avoid over-directing users  </li> <li>Controls give full access through joystick and manual controls that expose the rovers complete functionality  </li> <li>Durability and Comfort comes from a reinforced chassis and protected actuators and current-limited systems to handle rough use  </li> <li>Instruction uses optional on-demand help screens and tooltips instead of guided tutorials to keep a sense of freedom while offering some support  </li> </ul>"},{"location":"02-Concept-Design/Design/#concept-c-collaborative-science-rover","title":"Concept C: Collaborative Science Rover","text":"<p>The Collaborative Science Rover concept focuses on teamwork and shared problem-solving by letting multiple users simultaneously control different parts of the rover. Each person is responsible for a specific role like navigation or sensor operation or data analysis which encourages communication and collaboration. While this concept promotes social learning and mirrors how real scientific teams work it adds extra interface and coordination complexity that can be challenging if roles are not clearly defined.</p> <p></p>"},{"location":"02-Concept-Design/Design/#functional-distribution-across-team-members_2","title":"Functional Distribution Across Team Members","text":"<ul> <li>Internet-based two-way wireless communication handles multi-user session management and synchronized command handling and shared data streams  </li> <li>Human-machine interface provides role-based control panels and multi-screen or multi-input support and shared visual feedback  </li> <li>Sensor and actuator control partitions control of motors and robotic arm and cameras and sensors to different users  </li> <li>System integration and safety manages command arbitration and conflict resolution and system safeguards and fault handling across multiple operators  </li> </ul>"},{"location":"02-Concept-Design/Design/#design-justification_2","title":"Design Justification","text":"<ul> <li>Cues include role-specific visual indicators and shared status displays and alerts to communicate system state across users  </li> <li>Controls are segmented and mapped to user roles to prevent conflicting inputs  </li> <li>Durability and Comfort comes from robust mechanical design and software interlocks to protect hardware from simultaneous or conflicting commands  </li> <li>Instruction uses brief role introductions and cooperative task prompts to help users understand responsibilities and work together effectively  </li> </ul>"},{"location":"02-Concept-Design/Design/#selected-concept","title":"Selected Concept","text":"<ul> <li>We have chosen to select the Mission Rover (Concept A) for our project. </li> </ul> <p>Quick Summary:</p> <ul> <li> <p>Concept A is a mission-based rover where users complete simple tasks designed to familiarize them with the rover. This will be achieved by using communication signals such as audio/visual cues.</p> </li> <li> <p>We chose Concept A because it gives users clear goals and instructions, which makes the rover easier to understand and use. The mission-based design keeps users engaged with the rover and it ensures that the user gets the hang of how to use the rover.</p> </li> </ul>"},{"location":"02-Concept-Design/Design/#concept-selection-rationale","title":"Concept Selection Rationale","text":"<p>After comparing all three concepts on usability and educational value and durability and safety and how well they fit exhibit design guidelines the Mission Rover won out. It balances engagement with simplicity better than the others. We pulled in some ideas from the other concepts but the mission-based structure gave us the strongest foundation.</p>"},{"location":"02-Concept-Design/Design/#final-selected-concept-summary","title":"Final Selected Concept Summary","text":"<ul> <li>Clear indicators through multiple channels like visuals and audio  </li> <li>Simple controls that anyone can pick up  </li> <li>Built tough and safe for repeated use  </li> <li>Minimal instructions needed because the design guides users naturally  </li> </ul>"},{"location":"03-Project-Requirements/Project-requirements/","title":"Project Overview","text":""},{"location":"03-Project-Requirements/Project-requirements/#project-overview","title":"Project Overview","text":"<p>Through team discussions, we designed our rover to explore a simulated Martian environment. The rover is remotely operated and collects scientific and environmental data through a variety of sensors, including atmospheric pressure, temperature and humidity, hazard detection, imaging, and navigation/orientation sensors like IMU and odometry. </p> <p>To move across the terrain, the rover features 2-wheel drive with steering, with 4-wheel drive considered as a future enhancement. Most structural components, including the chassis, mounts, and body, are 3D printed for rapid prototyping and customization, while wheels, motors, electronics, and sensors are purchased from suppliers.</p> <p>All subsystems communicate through a daisy-chained UART network, allowing independent boards to send and receive messages safely. Remote operation is achieved through bidirectional wireless communication for real-time telemetry, video streaming, and manual control. A local Human\u2013Machine Interface consisting of pushbuttons, levers, and an OLED display, provides immediate system feedback without needing a remote connection.</p>"},{"location":"03-Project-Requirements/Project-requirements/#project-rationel","title":"Project Rationel","text":"<p>Our team designed this as an open-ended exploration platform focused on collecting real-time scientific data rather than following fixed tasks. It uses a modular setup with separate sensor, actuator, HMI, and communication boards, all connected through a daisy-chained UART network for reliable communication between subsystems. A local OLED display allows users to monitor data and adjust settings in real time, while safety features like an emergency stop, built-in fail-safes, and low-power operation are included to relate to real planetary rover designs.</p>"},{"location":"03-Project-Requirements/Project-requirements/#key-feature-to-requirement-mappings","title":"Key Feature-to-Requirement Mappings","text":"<p>Our rover is designed as an open-ended exploration platform, focused on collecting scientific data rather than performing fixed tasks. Each feature of the rover naturally leads to a set of requirements that ensure the system works as intended:</p> <ul> <li>Mobility: To explore the terrain effectively, the rover needs drive and steering capabilities. This translates to a requirement for 2WD with steering, and a stretch goal for 4WD.</li> <li>Scientific Exploration: To collect environmental data, the rover requires sensors for pressure, temperature, humidity, and navigation, all with calibrated outputs for real-time telemetry.</li> <li>Hazard Avoidance: Since the rover operates remotely, obstacle detection is required to prevent collisions. This includes alerts and, in advanced operation, automatic slow or stop behaviors.</li> <li>Imaging and Feedback: Cameras and video streaming provide situational awareness to the operator, which is critical for safe navigation and mission planning.</li> <li>User Interaction: A local OLED display and input buttons allow on-rover monitoring and control, providing redundancy if wireless control is lost.</li> <li>Modular Subsystem Integration: All subsystems need to communicate reliably via UART to ensure messages reach the correct module, allowing future expansion without reworking the network.</li> <li>Safety and Power Management: Emergency stops, fail-safes, and low-power operation are required to ensure both operator safety and system longevity.</li> </ul>"},{"location":"03-Project-Requirements/Project-requirements/#requirements-table","title":"Requirements Table","text":"Description Minimum Target Feature Satisfied Rover shall provide drive mobility with independent motor control Forward/backward motion on flat surfaces \u22650.1 m/s 2WD with variable speed control (0.1\u20130.5 m/s) Mobility (Drive) Rover shall implement steering control for directional navigation Basic turning using differential drive or simple steering Controlled steering with \u226530\u00b0 turning radius Mobility (Steering) Rover shall detect obstacles or hazards and alert or slow/stop Detect obstacles \u22640.5 m ahead and alert operator Detect \u22641.5 m with optional automatic slow/stop Hazard Avoidance, Safety Rover shall measure atmospheric pressure Functional basic barometric sensor Calibrated sensor (0\u20131100 hPa) Environmental Sensing (Pressure) Rover shall measure temperature and humidity Basic temperature (\u00b12 \u00b0C) and humidity sensing Continuous telemetry with \u00b11 \u00b0C, \u00b15% RH Environmental Sensing (Weather) Rover shall provide navigation and orientation data IMU provides heading and tilt Optional integration with wheel odometry for smoother navigation Navigation &amp; Orientation Rover shall capture and transmit imaging data Capture static images Real-time video streaming at low frame rate (\u22655 fps) Imaging &amp; Operator Feedback Two-way wireless communication shall enable remote control and telemetry Commands reach rover, basic telemetry returns Stable Wi-Fi/Bluetooth link with minimal delay Teleoperation &amp; Wireless Communication Rover shall provide a local human\u2013machine interface OLED shows basic status Menu-driven OLED with sensor data, alerts, and parameters Human\u2013Machine Interface (OLED) Rover chassis and major structural components shall be 3D printed Printable and assembles with purchased parts Lightweight, durable design for testing Mechanical Construction Power system shall support extended operation \u226530 minutes continuous operation ~60 minutes with monitoring and low-power modes Power Management System shall include emergency stop and fail-safe behaviors Physical switch or software stop works Automatic safe state with simple system alerts System Safety Communication network shall support all subsystem messaging Messages may be delayed occasionally Reliable messaging via UART/I2C between boards Modular Subsystem Integration Rover shall not exceed chassis weight limit Total weight \u22645 kg \u22644.5 kg for mobility efficiency Mechanical Construction &amp; Mobility Maximum current draw per subsystem Each subsystem \u22642 A Each subsystem \u22641.5 A Power Management &amp; Safety Environmental tolerance for sensors Functional indoors Functional outdoors, 0\u201340\u00b0C, 20\u201380% RH Environmental Sensing &amp; System Safety"},{"location":"03-Project-Requirements/Project-requirements/#requirement-assignment-to-team-members","title":"Requirement Assignment to Team Members","text":"Team Member Name Main Board Functions (Key Responsibilities) Primary Assignee (Subsystem) Member 1 Liam Mabbutt Rover drive mobility using 2WD baseline, 4WD may be added, motor speed control, steering control, motor feedback, and safety interlocks Mobility &amp; Motor Control Board Member 2 Myles White Obstacle and hazard detection using distance sensors, collision warnings, autonomous slow/stop requests, and safety alerts Obstacle Detection &amp; Safety Board Member 3 Isaiah Lacombe Environmental sensing including atmospheric pressure, temperature, and humidity measurement, calibration, and real-time telemetry Environmental Sensor Board Member 4 Ragul Raj RG Navigation and orientation sensing using IMU and optional wheel odometry, heading estimation, tilt detection, and motion data reporting Navigation &amp; Orientation Board Member 5 Arianna Lazaritt Imaging system control including camera operation, image/video capture, data packetization, and status reporting Imaging Board Member 6 Damian Novgorodov Two-way wireless communication (WiFi/Bluetooth), command routing between base station and rover subsystems, telemetry aggregation, and system messaging Wireless Communication Board Member 7 Christo Jomon Joseph Local human\u2013machine interface including OLED display, pushbuttons, rover status display, user input handling, power monitoring, emergency stop, and fail-safe control HMI &amp; System Safety Board"},{"location":"04-Team-Block-Diagram/Team-Diagram/","title":"Block Diagram, Protocol, and Message Structure","text":""},{"location":"04-Team-Block-Diagram/Team-Diagram/#1-team-block-diagram-overview","title":"1\ufe0f\u20e3 Team Block Diagram Overview","text":""},{"location":"04-Team-Block-Diagram/Team-Diagram/#environmental-sensor-subsystem-specification","title":"Environmental Sensor Subsystem Specification","text":"<p>Subsystem Designer: Isaiah LaCombe This document defines the message types, byte-level structures, and hardware-to-message mapping for the Environmental Sensor Subsystem.</p>"},{"location":"04-Team-Block-Diagram/Team-Diagram/#environmental-sensor-message-types-structures","title":"Environmental Sensor Message Types &amp; Structures","text":"Message Type Byte(s) Data Type Description 4 \u2013 Sensor Reading 1-2 uint16_t Message Type = 0x04 4 \u2013 Sensor Reading 3 uint8_t Sensor ID: 0 = Temperature, 1 = Humidity, 2 = Pressure 4 \u2013 Sensor Reading 4-5 int16_t Sensor value (scaled, e.g., temperature \u00d7100 for 2 decimals) 4 \u2013 Sensor Reading 6-61 char Optional telemetry string, null-terminated (e.g., <code>\"unit=Celsius\"</code>, <code>\"unit=hPa\"</code>) 11 \u2013 Subsystem Error 1-2 uint16_t Message Type = 0x0B 11 \u2013 Subsystem Error 3 uint8_t Error code: 1 = temperature sensor fail, 2 = humidity sensor fail, 3 = pressure sensor fail 12 \u2013 Subsystem Status Code 1-2 uint16_t Message Type = 0x0C 12 \u2013 Subsystem Status Code 3 uint8_t Status code: 0 = OK, 1 = calibration needed, 2 = sensor fault 13 \u2013 Subsystem Status Message 1-2 uint16_t Message Type = 0x0D 13 \u2013 Subsystem Status Message 3-58 char Status message, max 55 characters, null-terminated <p>sequenceDiagram     autonumber     %% Participants with full member names     participant WebUser     participant InPersonUser     participant Christo as \"Christo Jomon Joseph (HMI &amp; System Safety Board)\"     participant Isaiah as \"Isaiah Lacombe (Environmental Sensor Board)\"     participant Liam as \"Liam Mabbutt (Mobility &amp; Motor Control Board)\"     participant Ragul as \"Ragul Raj RG (Navigation &amp; Orientation Board)\"     participant Arianna as \"Arianna Lazaritt (Imaging Board)\"     participant Damian as \"Damian Novgorodov (Wireless Communication Board)\"     participant OLED as \"OLED Display\"</p>"},{"location":"04-Team-Block-Diagram/Team-Diagram/#part-2-sequence-diagram-of-team-communication","title":"Part 2: Sequence Diagram of Team Communication","text":"<p>This diagram shows a typical use case of team communication for the rover, including sensor updates, user interactions (web and in-person), motor commands, and message disposal. Each message type (4, 11, 12, 13) is represented in the hops.</p> <p>```mermaid sequenceDiagram     autonumber     %% Participants with full member names     participant WebUser     participant InPersonUser     participant Christo as \"Christo Jomon Joseph (HMI &amp; System Safety Board)\"     participant Isaiah as \"Isaiah Lacombe (Environmental Sensor Board)\"     participant Liam as \"Liam Mabbutt (Mobility &amp; Motor Control Board)\"     participant Ragul as \"Ragul Raj RG (Navigation &amp; Orientation Board)\"     participant Arianna as \"Arianna Lazaritt (Imaging Board)\"     participant Damian as \"Damian Novgorodov (Wireless Communication Board)\"     participant OLED as \"OLED Display\"</p> <pre><code>loop Every second\n    WebUser-&gt;&gt;Christo: Request turn on LED1\n    InPersonUser-&gt;&gt;Christo: Press button LED1\n    Christo-&gt;&gt;Isaiah: Command LED1 ON\n    Isaiah--&gt;&gt;Christo: LED1 On, trash message\n    Christo-&gt;&gt;OLED: Display LED1 status\n\n    Liam-&gt;&gt;Ragul: Set speed 200 m/s\n    Liam--&gt;&gt;Ragul: Confirm speed, trash message\n\n    Ragul-&gt;&gt;Everyone: My Speed is 300 m/s\n    OLED-&gt;&gt;WebUser: Display speed\n    OLED-&gt;&gt;InPersonUser: Display speed\n    Ragul--&gt;&gt;Everyone: Trash message\nend\n\n%% Event-driven environmental reading\nloop Sensor update (event-driven)\n    Isaiah-&gt;&gt;Liam: Sensor reading Msg Type 4 (Temp=23.56\u00b0C)\n    Liam-&gt;&gt;OLED: Update telemetry display\n    Isaiah-&gt;&gt;Christo: Environmental status Msg Type 12 (Status OK)\n    Christo-&gt;&gt;WebUser: Update web telemetry\n    Isaiah-&gt;&gt;Ragul: Environmental message Type 13 (Status message)\n    Ragul--&gt;&gt;Christo: Trash message after processing\nend\n\n%% Error handling example\nloop Error event\n    Isaiah-&gt;&gt;Christo: Msg Type 11, Temp sensor fail\n    Christo-&gt;&gt;OLED: Show error alert\n    Christo-&gt;&gt;WebUser: Web notification of error\n    Christo--&gt;&gt;Isaiah: Trash message\nend\n</code></pre>"},{"location":"Appendix/appendix/","title":"Appendix","text":""},{"location":"Appendix/appendix/#appendix-content","title":"Appendix Content","text":"<ul> <li>Appendix - Extra Team Organization Information</li> </ul>"},{"location":"Appendix/01-Organization-Information/Append-Organization/","title":"Appendix - Extra Team Organization Information","text":""},{"location":"Appendix/01-Organization-Information/Append-Organization/#project-roles-and-duties","title":"Project Roles and Duties","text":"Role Duties Member Meeting leader Schedules team meetings, creates and distributes an agenda for each meeting, and runs each meeting Damian Novgorodov Meeting recorder Takes minutes of each team meeting, including attendance, and records action items and to whom they are assigned Christo Joseph Assignment leader Coordinates the team's work on a given assignment to Canvas before the due date Ragul Raj Project monitor Tracks the team's progress relative to the project schedule (Gantt chart) and keeps team members apprised of deadlines and project status Miles Technical lead Reviews designs, code, and decisions for consistency, helps debug issues, and keeps technical direction aligned. Liam Documentation lead Manages reports, write-ups, diagrams, and formatting to keep submissions clean, organized, and rubric-compliant. Isaiah Quality assurance / tester Tests the project before demos or submission to check requirements, bugs, and edge cases and verify specs are met. Arianna <p>Roles were initially assigned based on each member's strengths, interests, and availability during an initial team discussion, with the current assignments shown in the table above. To ensure everyone has the opportunity to participate fully, roles will rotate every 3 weeks. Team members will help one another meet their responsibilities by communicating through Discord and text to offer assistance and collaborate on tasks that overlap between roles. If a team member is struggling or unavailable, the issue will be raised in a team meeting and responsibilities will be redistributed through group discussion and majority vote. The project monitor will track team activities and milestones using a Gantt chart and keep everyone updated on deadlines and progress through regular check-ins in the group chat. Technical responsibilities will be divided based on individual expertise and interest.</p>"},{"location":"Appendix/01-Organization-Information/Append-Organization/#communication-channels","title":"Communication Channels","text":""},{"location":"Appendix/01-Organization-Information/Append-Organization/#team-member-info","title":"Team Member Info","text":"Team Member First Choice Communication Second Choice Communication Third Choice Communication Damian Text Zoom/Call Email Miles Text Zoom/Call Email Isaiah Text Zoom/Call Email Arianna Text Zoom/Call Email Raj Text Zoom/Call Email Christo Text Zoom/Call Email Liam Text Zoom/Call Email"},{"location":"Appendix/01-Organization-Information/Append-Organization/#team-accountability-and-coordination","title":"Team Accountability and Coordination","text":""},{"location":"Appendix/01-Organization-Information/Append-Organization/#communication-plan","title":"Communication Plan","text":"<p>Methods: We will use Discord as our primary tool for both asynchronous (chat/updates) and synchronous (voice calls) communication. We will also have a group text chat as a backup for urgent alerts. We are avoiding other apps to keep things simple.</p> <p>Instructor Correspondence: The Team Lead is responsible for emailing the instructor. Any replies will be screenshotted and posted in the Discord \"Announcements\" channel so the whole team sees the information immediately.</p> <p>File Sharing: We have created a shared Google Drive folder for all project files, reports, and assets, following the required naming conventions.</p>"},{"location":"Appendix/01-Organization-Information/Append-Organization/#meeting-schedule-and-coordination","title":"Meeting Schedule and Coordination","text":"<p>The team discussed and created a project schedule, which can be found here.</p> <p>Availability: We identified that everyone is generally available on weekends and weekdays after 7:00 PM.</p> <p>Weekly Slot: Our standing weekly meeting will be Tuesdays at 7:30 PM.</p> <p>Format: These meetings will be virtual (via Discord Voice) to save travel time, but we can meet in person at the lab on weekends if hardware testing is needed.</p> <p>Reminders: We will send a \"pinned\" mention in the Discord chat 1 hour before the meeting.</p> <p>Changes: Since we are all adults, if a time needs to change, a member must request the change in the group chat at least 24 hours in advance so we can adjust.</p>"},{"location":"Appendix/01-Organization-Information/Append-Organization/#team-coordination-accountability","title":"Team Coordination &amp; Accountability","text":"<p>Submission &amp; Skills: Before any assignment is submitted, we will post the draft in Discord for a \"thumbs up\" sign-off from all members. If a member lacks the specific skill for a task (e.g., coding or PCB design), they will pair up with a more experienced member to learn, ensuring no one is left behind.</p> <p>Design Reviews: Feedback received from design reviews will be listed as \"Action Items\" in our Google Doc, and specific members will be assigned to fix them before the next meeting.</p> <p>Addressing Underperformance:</p> <ul> <li>First Miss: We will reach out to remind them and ask if everything is okay.</li> <li>Support: If they are struggling, we will schedule a working session to catch them up.</li> <li>Consequences: If a member repeatedly ignores help, ghosts the team, or fails to contribute after warnings, we will resort to a pink slip to protect the team's grade.</li> </ul>"},{"location":"Appendix/01-Organization-Information/Append-Organization/#conflict-recognition-resolution","title":"Conflict Recognition &amp; Resolution","text":"<p>Disagreements: We acknowledge that engineering involves different opinions. When we disagree on a design choice, we will discuss the technical pros and cons of each option.</p> <p>Resolution: If we cannot agree after a discussion, we will rely on a majority vote to move forward.</p> <p>Role Conflicts: We will avoid conflicts of interest by clearly sticking to the roles defined in our Charter (e.g., The Actuation Lead makes final calls on motors).</p> <p>Escalation: We will only involve the instructor if a conflict completely halts our progress or if a team member becomes hostile/unprofessional.</p>"},{"location":"Appendix/02-Concept-Genrations/Append-Concepts/","title":"Appendix - Design Concepts","text":""},{"location":"Appendix/02-Concept-Genrations/Append-Concepts/#header","title":"Header","text":"<p>Add text for assignment as needed or delete page!</p>"},{"location":"Appendix/03-Examples-to-Hide/charts/","title":"Charts","text":"<pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre> <pre><code>sequenceDiagram\n  autonumber\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n      John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!</code></pre> <pre><code>stateDiagram-v2\n  state fork_state &lt;&lt;fork&gt;&gt;\n    [*] --&gt; fork_state\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    state join_state &lt;&lt;join&gt;&gt;\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n    join_state --&gt; State4\n    State4 --&gt; [*]</code></pre>"},{"location":"Appendix/03-Examples-to-Hide/esp-32-table/","title":"ESP32 Table","text":"ESP Info Answer Help Model ? Include the entire part number (leave off any letters at the end that specify the package type) Product Page URL ? Found on Espressif.com ESP32-S3-WROOM-1-N4 Datasheet URL ? Do not paste links directly into the table.  Use a link ESP32 S3 Datasheet URL ? Has more detail on functions ESP32 S3 Technical Reference Manual URL ? Has details on I/O multiplexing, USB, and others Vendor link ? Digikey, Jameco, etc.  Do not paste links directly into the table.  Use a link Code Examples ? url(s) for libraries on github or other sites related to the microcontroller and your planned peripherals External Resources URL(s) ? Search on Google and YouTube for other resources for each specific microcontroller. Unit cost ? Find on Digikey, Jameco, MPJA, or octopart Absolute Maximum Current for entire IC ? Find in the microcontroller datasheet Supply Voltage Range ? Min / Nominal / Max / Absolute Max, as found in datasheet Absolute Maximum current  (for entire IC) ? as found in datasheet Maximum GPIO current  (per pin) ? as found in datasheet Supports External Interrupts? ? as found in datasheet Required Programming Hardware, Cost, URL ? as found in datasheet Module # Available Needed Associated Pins (or * for any) UART ? ? ? external SPI* ? ? ? I2C ? ? ? GPIO ? ? ? ADC ? ? ? LED PWM ? ? ? Motor PWM ? ? ? USB Programmer ? 1 ? ... <p>* The ESP32-S2 has multiple SPI interfaces, but some are for internal use</p>"}]}